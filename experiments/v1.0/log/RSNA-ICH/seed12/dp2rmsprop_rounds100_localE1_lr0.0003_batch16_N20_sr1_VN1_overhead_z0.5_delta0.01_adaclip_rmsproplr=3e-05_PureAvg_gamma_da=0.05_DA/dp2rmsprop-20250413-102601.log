[10:26:01.364] [Client 0] Train=750, Val=250, Test=250
[10:26:01.365] [Client 1] Train=750, Val=250, Test=250
[10:26:01.366] [Client 2] Train=750, Val=250, Test=250
[10:26:01.366] [Client 3] Train=750, Val=250, Test=250
[10:26:01.367] [Client 4] Train=750, Val=250, Test=250
[10:26:01.368] [Client 5] Train=750, Val=250, Test=250
[10:26:01.368] [Client 6] Train=750, Val=250, Test=250
[10:26:01.369] [Client 7] Train=750, Val=250, Test=250
[10:26:01.370] [Client 8] Train=750, Val=250, Test=250
[10:26:01.370] [Client 9] Train=750, Val=250, Test=250
[10:26:01.371] [Client 10] Train=750, Val=250, Test=250
[10:26:01.372] [Client 11] Train=750, Val=250, Test=250
[10:26:01.373] [Client 12] Train=750, Val=250, Test=250
[10:26:01.373] [Client 13] Train=750, Val=250, Test=250
[10:26:01.374] [Client 14] Train=750, Val=250, Test=250
[10:26:01.375] [Client 15] Train=750, Val=250, Test=250
[10:26:01.376] [Client 16] Train=750, Val=250, Test=250
[10:26:01.376] [Client 17] Train=750, Val=250, Test=250
[10:26:01.377] [Client 18] Train=750, Val=250, Test=250
[10:26:01.378] [Client 19] Train=750, Val=250, Test=250
[10:26:01.378] [Virtual Client 0-0] Train=750
[10:26:01.379] [Virtual Client 1-0] Train=750
[10:26:01.379] [Virtual Client 2-0] Train=750
[10:26:01.380] [Virtual Client 3-0] Train=750
[10:26:01.381] [Virtual Client 4-0] Train=750
[10:26:01.382] [Virtual Client 5-0] Train=750
[10:26:01.382] [Virtual Client 6-0] Train=750
[10:26:01.383] [Virtual Client 7-0] Train=750
[10:26:01.384] [Virtual Client 8-0] Train=750
[10:26:01.385] [Virtual Client 9-0] Train=750
[10:26:01.386] [Virtual Client 10-0] Train=750
[10:26:01.386] [Virtual Client 11-0] Train=750
[10:26:01.387] [Virtual Client 12-0] Train=750
[10:26:01.388] [Virtual Client 13-0] Train=750
[10:26:01.389] [Virtual Client 14-0] Train=750
[10:26:01.390] [Virtual Client 15-0] Train=750
[10:26:01.391] [Virtual Client 16-0] Train=750
[10:26:01.392] [Virtual Client 17-0] Train=750
[10:26:01.393] [Virtual Client 18-0] Train=750
[10:26:01.394] [Virtual Client 19-0] Train=750
[10:26:01.401] Client Weights: [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]
[10:26:01.402] Training Clients:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[10:26:01.403] Val Clients:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[10:26:01.403] =============== args ================
[10:26:01.404] Namespace(clients=20, virtual_clients=1, lr=0.0003, lr_decay=-1, early=False, batch=16, rounds=100, local_epochs=1, mode='dp2rmsprop', pretrain=False, exp=None, save_path='../../experiments/v1.0/checkpoint/RSNA-ICH/seed12/dp2rmsprop_rounds100_localE1_lr0.0003_batch16_N20_sr1_VN1_overhead_z0.5_delta0.01_adaclip_rmsproplr=3e-05_PureAvg_gamma_da=0.05_DA', resume=False, gpu='0', seed=12, debug=False, data='RSNA-ICH', sample_rate=1, leave='no', merge=False, balance=False, weighted_avg=False, split='UNI', local_bn=False, generalize=False, gn=False, selu=False, comb='times', free=-1, noisy=-1, alpha=1.0, adaclip=True, noclip=False, ema=0.0, mu=0.001, S=10, epsilon=None, noise_multiplier=0.5, delta=0.01, accountant='prv', dp_mode='overhead', balance_split=False, test=False, ckpt='None', adam_lr=0.1, dp2_interval=3, rmsprop_lr=3e-05, ada_vn=False, init_vn=False, ada_stable=False, ada_prog=False, gamma_da=0.05, class_weights=None, domain_adaptation=True, init_lambda=0.005, lambda_schedule='linear', domain_lr=0.0001, log_path='../../experiments/v1.0/log/RSNA-ICH/seed12/dp2rmsprop_rounds100_localE1_lr0.0003_batch16_N20_sr1_VN1_overhead_z0.5_delta0.01_adaclip_rmsproplr=3e-05_PureAvg_gamma_da=0.05_DA')
[10:26:09.927] Using noise multiplier=0.5 and sigma on aggregation=0.25 to satisfy (245.5990192385698,0.01)-DP.
[10:26:09.928] Using adaptive clipping.
[10:26:09.928] Using prv accountant.
[10:26:09.932] Using domain loss weight (gamma): 0.05
[10:26:10.009] ============ Round 0, Local train epoch 0 ============
